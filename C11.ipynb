{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers, activations, optimizers, losses, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Vectorizer:\n",
    "    '''A dummy text vectorizer'''\n",
    "\n",
    "    def standardize(self, text:str) -> str:\n",
    "        text = text.lower()\n",
    "        text_without_punctuations = [char for char in text if char not in string.punctuation]\n",
    "        return ''.join(text_without_punctuations)\n",
    "    \n",
    "    def tokenize(self, text:str) -> str:\n",
    "        text = self.standardize(text)\n",
    "        return text.split()\n",
    "    \n",
    "    def make_vocabulary(self, dataset):\n",
    "        self.vocabulary = {'' : 0,\n",
    "                           '[UNK]' : 1}\n",
    "        for text in dataset:\n",
    "            text = self.standardize(text)\n",
    "            tokens = self.tokenize(text)\n",
    "\n",
    "            for token in tokens:\n",
    "                if token not in self.vocabulary:\n",
    "                    self.vocabulary[token] = len(self.vocabulary)\n",
    "        \n",
    "        self.inverse_vocabulary = {value: key for key, value in self.vocabulary.items()}\n",
    "    \n",
    "    def encode(self, text:str) -> list:\n",
    "        text = self.standardize(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        return [self.vocabulary.get(token, 1) for token in tokens]\n",
    "    \n",
    "    def decode(self, sequence:list) -> str:\n",
    "        return ' '.join([self.inverse_vocabulary.get(item, '[UNK]') for item in sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[UNK]': 1,\n",
       " 'i': 2,\n",
       " 'write': 3,\n",
       " 'erase': 4,\n",
       " 'rewrite': 5,\n",
       " 'again': 6,\n",
       " 'and': 7,\n",
       " 'then': 8,\n",
       " 'a': 9,\n",
       " 'poppy': 10,\n",
       " 'blooms': 11}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ['I write, erase, rewrite', 'Erase again and then', 'A poppy blooms']\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "vectorizer.make_vocabulary(dataset)\n",
    "\n",
    "vectorizer.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 7, 1, 5, 6]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'I write, rewrite, and still rewrite again'\n",
    "encoded = vectorizer.encode(sample)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i write rewrite and [UNK] rewrite again'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = vectorizer.decode(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keras TextVectorization layer\n",
    "\n",
    "text_vectorization = keras.layers.TextVectorization(output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'erase',\n",
       " 'write',\n",
       " 'then',\n",
       " 'rewrite',\n",
       " 'poppy',\n",
       " 'i',\n",
       " 'blooms',\n",
       " 'and',\n",
       " 'again',\n",
       " 'a']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom standardizer and tokenizer for TextVectorization\n",
    "\n",
    "def custom_standardization_function(text:str) -> tf.strings:\n",
    "    text = tf.strings.lower(text)\n",
    "    text_without_punctuations = tf.strings.regex_replace(text, f'[{re.escape(string.punctuation)}]', '')\n",
    "    return text_without_punctuations\n",
    "\n",
    "def custom_tokenizer(text:tf.strings) -> tf.Tensor:\n",
    "    return tf.strings.split(text)\n",
    "\n",
    "text_vectorization = keras.layers.TextVectorization(output_mode='int',\n",
    "                                                    standardize=custom_standardization_function,\n",
    "                                                    split=custom_tokenizer)\n",
    "\n",
    "text_vectorization.adapt(dataset)\n",
    "text_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([ 7,  3,  5,  9,  1,  5, 10])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'I write, rewrite, and still rewrite again'\n",
    "text_vectorization(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: TextVectorization cannot utilize GPU as it is mostly a dictionary lookup operation\n",
    "\n",
    "# Approach 1 (performant): Put it in the tf.data pipeline. This happens asynchronously. This enables CPU to perform vectorization on batch_n+1 while GPU is training a batch_n.\n",
    "sequences = dataset.map(text_vectorization, num_parallel=4)\n",
    "\n",
    "# Approach 2 (flexible): Put is as a layer in the model. The GPU has to wait for this operation for every batch. However, this is easier to deploy in production environments, otherwise you might have to incorporate the logic in Javascript into the deployed model.\n",
    "text_input = keras.Input(shape=(), dtype='string')\n",
    "vectorized_text = keras.layers.TextVectorization(text_input)\n",
    "embedded_input = keras.layers.Embedding(...)(vectorized_text)\n",
    "output = ...\n",
    "model = keras.Model(text_input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-19 07:26:28--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz’\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  3.75MB/s    in 24s     \n",
      "\n",
      "2023-12-19 07:26:52 (3.29 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Collect and uncompress the ACL IMDB Movie Reviews dataset\n",
    "\n",
    "# !wget 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "# !tar -xf aclImdb_v1.tar.gz\n",
    "\n",
    "# # Delete the Unsupervised training samples, we don't need them\n",
    "\n",
    "# !rm -r aclImdb/train/unsup\n",
    "\n",
    "# # Move it to data\n",
    "# !mv aclImdb data/aclImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path('data/aclImdb')\n",
    "val_dir = base_dir / 'val'\n",
    "train_dir = base_dir / 'train'\n",
    "\n",
    "for category in ('neg', 'pos'):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname, \n",
    "                    val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory('data/aclImdb/train', batch_size=batch_size)\n",
    "val_ds = keras.utils.text_dataset_from_directory('data/aclImdb/val', batch_size=batch_size)\n",
    "test_ds = keras.utils.text_dataset_from_directory('data/aclImdb/test', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapshot(dataset):\n",
    "    for inputs, targets in dataset:\n",
    "        print('inputs.shape:', inputs.shape)\n",
    "        print('inputs.dtype:', inputs.dtype)\n",
    "        print('targets.shape:', targets.shape)\n",
    "        print('targets.dtype:', targets.dtype)\n",
    "        print('inputs[0]:', inputs[0])\n",
    "        print('targets[0]:', targets[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'Although I love this movie, I can barely watch it, it is so real. So, I put it on tonight and hid behind my bank of computers. I remembered it vividly, but just wanted to see if I could find something I hadn\\'t seen before........I didn\\'t: that\\'s because it\\'s so real to me.<br /><br />Another \"user\" wrote the ages of the commentators should be shown with their summary. I\\'m all for that ! It\\'s absolutely obvious that most of these people who\\'ve made comments about \"Midnight Cowboy\" may not have been born when it was released. They are mentioning other movies Jon Voight and Dustin Hoffman have appeared in, at a later time. I\\'ll be just as ruinously frank: I am 82-years-old. If you\\'re familiar with some of my other comments, you\\'ll be aware that I was a professional female-impersonator for 60 of those years, and also have appeared in film - you\\'d never recognize me, even if you were familiar with my night-club persona. Do you think I know a lot about the characters in this film ? YOU BET I DO !!....<br /><br />....and am not the least bit ashamed. If you haven\\'t run-into some of them, it\\'s your loss - but, there\\'s a huge chance you have, but just didn\\'t know it. So many moms, dads, sons and daughters could surprise you. It should be no secret MANY actors/actresses have emerged from the backgrounds of \"Midnight Cowboy\". Who is to judge ? I can name several, current BIG-TIME stars who were raised on the seedy streets of many cities, and weren\\'t the least bit damaged by their time spent there. I make no judgment, because these are humans, just as we all are - love, courage, kindness, compassion, intelligence, humility: you name the attributes, they are all there, no matter what the package looks like.<br /><br />The \"trivia\" about Hoffman actually begging on the streets to prove he could do the role of \"Ratzo\" is a gem - he can be seen driving his auto all around Los Angeles - how do you think he gets his input? I can also name lots of male-stars who have stood on the streets and cruised the bars for money. Although the nightclub I last worked in for 26 years was world-famous and legit, I can also name some HUGE stars that had to be constantly chased out our back-street, looking to make a pick-up.<br /><br />This should be no surprise today, although it\\'s definitely action in Hollywood and other cities, large and small. Wake-up and smell the roses. They smell no less sweet because they are of a different hue.<br /><br />Some of the \"users\" thought \"Joe Buck\" had been molested by his grandma. Although I saw him in her bed with a boyfriend, I didn\\'t find any incidence of that. Believe-it-or-not, kids haven\\'t ALWAYS had their own rooms - because that is a must today should tell you something kinda kinky may be going-on in the master-bedroom. Whose business? Hoffman may have begged for change on the streets, but some of the \"users\" point-out that Jon Voight was not a major star for the filming of \"Midnight Cowboy\" - his actual salary would surprise you. I think he was robbed ! No one can doubt the clarity he put into his role, nor that it MADE him a star for such great work as \"Deliverance\". He defined a potent man who had conquered his devils and was the better for it: few people commented he had been sodomized in this movie. The end of the 60s may have been one of the first films to be so open, but society has always been hip.<br /><br />I also did not find any homosexuality between \"Ratzo\" and \"Joe\" - they were clearly opposites, unappealing to one another. They found a much purely higher relationship - true friendship. If you didn\\'t understand that at the end of the movie, then you\\'ve wasted your time. \"Joe\\'s\" bewilderment, but unashamed devotion was apparent. Yes, Voight deserved an Oscar for this role - one that John Wayne could never pull-off, and he was as handsome in his youth.<br /><br />Hoffman is Hoffman - you expect fireworks. He gave them superbly. Wayne got his Oscar. Every character in this film was beautifully defined - if you don\\'t think they are still around, you are mistaken. \"The party\" ? - attend some of the \"raves\" younger people attend.....if you can get in. Look at the lines of people trying to get into the hot clubs - you\\'ll see every outrageous personality.<br /><br />Brenda Viccaro was the epitome of society\\'s sleek women who have to get down to the nitty-gritty at times. If you were shocked by her brilliant acting, thinking \"this isn\\'t real\", look at today\\'s \"ladies\" who live on the brink of disrepute....and are admired for it.<br /><br />The brutality \"Joe\" displayed in robbing the old guy, unfortunately, is also a part of life. You don\\'t have to condone it, but it\\'s not too much different than any violence. \"Joe\" pointedly named his purpose - in that situation, I\\'d have handed-over the money quicker than he asked for it. That\\'s one of the scenes that makes this movie a break-through, one which I do not watch. I get heartbroken for both.....<br /><br />John Schlesinger certainly must have been familiar with this sordidness to direct this chillingly beautiful eye-opener- Waldo Salt didn\\'t write from clairvoyance. Anyone who had any part of getting it to the screen must have realized they were making history, and should be proud for the honesty of it. Perhaps \"only in America\" can we close our eyes to unpleasant situations, while other movie-makers make no compunction in presenting it to the public. Not looking doesn\\'t mean it isn\\'t there - give me the truth every time. Bravo! to all......', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "snapshot(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two text representations: Ordered Sequences (Sequence Models) and Unordered Sets (Bag of Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the Bag of Words approach first, using unigrams\n",
    "\n",
    "text_vectorization = TextVectorization(max_tokens=20000,                      # Limit vocabulary to 20000 most frequent words\n",
    "                                       output_mode='multi_hot')               # Encode output tokens as multi-hot binary vectors\n",
    "\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_1gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_1gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_1gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'float32'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "snapshot(binary_1gram_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation=activations.relu)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=optimizers.RMSprop(),\n",
    "                loss=losses.BinaryCrossentropy(),\n",
    "                metrics=[metrics.BinaryAccuracy()])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_bow_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.1859 - binary_accuracy: 0.9340 - val_loss: 0.2731 - val_binary_accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.1619 - binary_accuracy: 0.9438 - val_loss: 0.2790 - val_binary_accuracy: 0.8964\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.1447 - binary_accuracy: 0.9509 - val_loss: 0.2853 - val_binary_accuracy: 0.8970\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.1311 - binary_accuracy: 0.9557 - val_loss: 0.2915 - val_binary_accuracy: 0.8960\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.1202 - binary_accuracy: 0.9590 - val_loss: 0.2966 - val_binary_accuracy: 0.8974\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.1110 - binary_accuracy: 0.9625 - val_loss: 0.3026 - val_binary_accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1036 - binary_accuracy: 0.9653 - val_loss: 0.3081 - val_binary_accuracy: 0.8980\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0969 - binary_accuracy: 0.9683 - val_loss: 0.3131 - val_binary_accuracy: 0.8960\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0909 - binary_accuracy: 0.9704 - val_loss: 0.3183 - val_binary_accuracy: 0.8958\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0857 - binary_accuracy: 0.9720 - val_loss: 0.3235 - val_binary_accuracy: 0.8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28de170d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/binary_1gram.keras')]\n",
    "\n",
    "model.fit(binary_1gram_train_ds.cache(),\n",
    "          validation_data=binary_1gram_val_ds.cache(),\n",
    "          epochs=10,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3807 - binary_accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8791600465774536"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/binary_1gram.keras')\n",
    "model.evaluate(binary_1gram_test_ds)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bag of words, using 2-grams\n",
    "\n",
    "text_vectorization = TextVectorization(ngrams=2,\n",
    "                                       max_tokens=20000,\n",
    "                                       output_mode='multi_hot')\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_2gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "\n",
    "model = get_bow_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.3628 - binary_accuracy: 0.8466 - val_loss: 0.2478 - val_binary_accuracy: 0.9048\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.1514 - binary_accuracy: 0.9497 - val_loss: 0.2497 - val_binary_accuracy: 0.9052\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0856 - binary_accuracy: 0.9742 - val_loss: 0.2722 - val_binary_accuracy: 0.9056\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0538 - binary_accuracy: 0.9839 - val_loss: 0.3007 - val_binary_accuracy: 0.9034\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0368 - binary_accuracy: 0.9895 - val_loss: 0.3331 - val_binary_accuracy: 0.9050\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0262 - binary_accuracy: 0.9930 - val_loss: 0.3626 - val_binary_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0201 - binary_accuracy: 0.9947 - val_loss: 0.3872 - val_binary_accuracy: 0.9010\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0155 - binary_accuracy: 0.9961 - val_loss: 0.4109 - val_binary_accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0128 - binary_accuracy: 0.9964 - val_loss: 0.4379 - val_binary_accuracy: 0.9010\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0107 - binary_accuracy: 0.9974 - val_loss: 0.4552 - val_binary_accuracy: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2fcbd9910>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/binary_2gram.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(binary_2gram_train_ds.cache(),\n",
    "          validation_data=binary_2gram_val_ds.cache(),\n",
    "          epochs=10,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2669 - binary_accuracy: 0.8947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8946800827980042"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/binary_2gram.keras')\n",
    "model.evaluate(binary_2gram_test_ds)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.9944 - binary_accuracy: 0.7630 - val_loss: 0.2852 - val_binary_accuracy: 0.8986\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.3199 - binary_accuracy: 0.9098 - val_loss: 0.2839 - val_binary_accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1702 - binary_accuracy: 0.9530 - val_loss: 0.3262 - val_binary_accuracy: 0.9042\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.1046 - binary_accuracy: 0.9711 - val_loss: 0.3392 - val_binary_accuracy: 0.9094\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0688 - binary_accuracy: 0.9824 - val_loss: 0.3833 - val_binary_accuracy: 0.9018\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0541 - binary_accuracy: 0.9872 - val_loss: 0.4056 - val_binary_accuracy: 0.9080\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0433 - binary_accuracy: 0.9911 - val_loss: 0.4372 - val_binary_accuracy: 0.9066\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0361 - binary_accuracy: 0.9928 - val_loss: 0.5942 - val_binary_accuracy: 0.8870\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0323 - binary_accuracy: 0.9943 - val_loss: 0.4997 - val_binary_accuracy: 0.9022\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.0279 - binary_accuracy: 0.9947 - val_loss: 0.5141 - val_binary_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28fd64b50>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of words, using 2-grams and TF-IDF encoding\n",
    "\n",
    "text_vectorization = TextVectorization(ngrams=2,\n",
    "                                       max_tokens=20000,\n",
    "                                       output_mode='tf_idf')\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "tfidf_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "tfidf_2gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "tfidf_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "\n",
    "model = get_bow_model()\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/tfidf_2gram.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(tfidf_2gram_train_ds.cache(),\n",
    "          validation_data=tfidf_2gram_val_ds.cache(),\n",
    "          epochs=10,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3149 - binary_accuracy: 0.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8961600661277771"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/tfidf_2gram.keras')\n",
    "model.evaluate(tfidf_2gram_test_ds)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.285% positive\n"
     ]
    }
   ],
   "source": [
    "# Example of using text vectorization as part of a model training pipeline (Approach 2 as mentioned before)\n",
    "\n",
    "inputs = keras.Input(shape=(1,), dtype='string')\n",
    "processed_inputs = text_vectorization(inputs)\n",
    "outputs = model(processed_inputs)\n",
    "\n",
    "inference_model = keras.Model(inputs, outputs)\n",
    "\n",
    "raw_text_data = tf.convert_to_tensor([['That was an excellent movie, I love it!'],])\n",
    "predictions = inference_model(raw_text_data)\n",
    "\n",
    "print(f'{float(predictions[0] * 100):.3f}% positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 600)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(\n",
      "[    4   244    37  4231  3335  2720 12922     3    40   512  1541 12923\n",
      "    26  1602    76     4   378   492     3   217   825    17     4   373\n",
      "  1708  3941     1    65  7866   611     4  1290   247     1 18668     3\n",
      "    29   533     5     4   199     1    13   861    38  2420    11     7\n",
      "     4    85    20    18    37  2305    30    38    53   252    13    13\n",
      "  1126   181  1206  9262   603    81  4337    46    43  5711  3335   208\n",
      "    85  2982   208   100    73  3361     6     1    13    38   409    23\n",
      "    77   347    11     4   169     9   468   821    23  1195    23  2284\n",
      "    23    41  4213    23     8    98    97    18     9    77   384    23\n",
      "  2311     3  1092     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "\n",
    "text_vectorization = layers.TextVectorization(max_tokens=max_tokens,\n",
    "                                              output_mode='int',\n",
    "                                              output_sequence_length=max_length)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "\n",
    "snapshot(int_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                5128448   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5128513 (19.56 MB)\n",
      "Trainable params: 5128513 (19.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 200s 315ms/step - loss: 0.5771 - binary_accuracy: 0.6949 - val_loss: 0.3871 - val_binary_accuracy: 0.8602\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 192s 308ms/step - loss: 0.3696 - binary_accuracy: 0.8611 - val_loss: 0.3233 - val_binary_accuracy: 0.8732\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 193s 309ms/step - loss: 0.3008 - binary_accuracy: 0.8938 - val_loss: 0.2800 - val_binary_accuracy: 0.8896\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 193s 309ms/step - loss: 0.2587 - binary_accuracy: 0.9114 - val_loss: 0.3472 - val_binary_accuracy: 0.8484\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.2248 - binary_accuracy: 0.9237 - val_loss: 0.3179 - val_binary_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.1950 - binary_accuracy: 0.9340 - val_loss: 0.2828 - val_binary_accuracy: 0.8968\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.1707 - binary_accuracy: 0.9432 - val_loss: 0.3949 - val_binary_accuracy: 0.8896\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 193s 309ms/step - loss: 0.1542 - binary_accuracy: 0.9501 - val_loss: 0.3180 - val_binary_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.1238 - binary_accuracy: 0.9604 - val_loss: 0.3617 - val_binary_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 193s 308ms/step - loss: 0.1076 - binary_accuracy: 0.9658 - val_loss: 0.3565 - val_binary_accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2de258290>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/one_hot_bidirectional_lstm.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(int_train_ds,\n",
    "          epochs=10,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 129s 164ms/step - loss: 0.3190 - binary_accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8658800721168518"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/one_hot_bidirectional_lstm.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 64)                73984     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5194049 (19.81 MB)\n",
      "Trainable params: 5194049 (19.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 114s 176ms/step - loss: 0.5248 - binary_accuracy: 0.7373 - val_loss: 0.4363 - val_binary_accuracy: 0.8046\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 93s 149ms/step - loss: 0.3547 - binary_accuracy: 0.8613 - val_loss: 0.3099 - val_binary_accuracy: 0.8792\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 91s 146ms/step - loss: 0.2787 - binary_accuracy: 0.8977 - val_loss: 0.3011 - val_binary_accuracy: 0.8836\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.2302 - binary_accuracy: 0.9197 - val_loss: 0.4371 - val_binary_accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.1968 - binary_accuracy: 0.9328 - val_loss: 0.4253 - val_binary_accuracy: 0.8648\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.1664 - binary_accuracy: 0.9433 - val_loss: 0.4481 - val_binary_accuracy: 0.8628\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.1469 - binary_accuracy: 0.9500 - val_loss: 0.3658 - val_binary_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 87s 138ms/step - loss: 0.1223 - binary_accuracy: 0.9622 - val_loss: 0.4150 - val_binary_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 86s 138ms/step - loss: 0.1077 - binary_accuracy: 0.9676 - val_loss: 0.3684 - val_binary_accuracy: 0.8704\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 86s 137ms/step - loss: 0.0900 - binary_accuracy: 0.9714 - val_loss: 0.4571 - val_binary_accuracy: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0xb044db0d0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/embeddings_bidirectional_lstm.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(int_train_ds,\n",
    "          epochs=10,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 30s 38ms/step - loss: 0.3385 - binary_accuracy: 0.8593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8593200445175171"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/embeddings_bidirectional_lstm.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_16 (Embedding)    (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirect  (None, 64)                73984     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5194049 (19.81 MB)\n",
      "Trainable params: 5194049 (19.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Masking (mask parameter in embedding layer) is used to mask out trailing zeros, stopping the model from learning false representations from them\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 189s 292ms/step - loss: 0.6947 - binary_accuracy: 0.5020 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 148s 237ms/step - loss: 0.6935 - binary_accuracy: 0.5071 - val_loss: 0.6928 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 144s 230ms/step - loss: 0.6931 - binary_accuracy: 0.5070 - val_loss: 0.6926 - val_binary_accuracy: 0.5004\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 0.6927 - binary_accuracy: 0.5031 - val_loss: 0.6924 - val_binary_accuracy: 0.5008\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 139s 223ms/step - loss: 0.6924 - binary_accuracy: 0.5081 - val_loss: 0.6923 - val_binary_accuracy: 0.5016\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 137s 218ms/step - loss: 0.6918 - binary_accuracy: 0.5039 - val_loss: 0.6919 - val_binary_accuracy: 0.5088\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 139s 222ms/step - loss: 0.6909 - binary_accuracy: 0.5053 - val_loss: 0.6922 - val_binary_accuracy: 0.5016\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 142s 227ms/step - loss: 0.6885 - binary_accuracy: 0.5196 - val_loss: 0.6921 - val_binary_accuracy: 0.5006\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 149s 239ms/step - loss: 0.6857 - binary_accuracy: 0.5169 - val_loss: 0.6945 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 157s 251ms/step - loss: 0.6811 - binary_accuracy: 0.5137 - val_loss: 0.7011 - val_binary_accuracy: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x9b7ab3f10>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/embeddings_bidirectional_lstm_masking.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(int_train_ds,\n",
    "          epochs=10,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 52s 63ms/step - loss: 0.6929 - binary_accuracy: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5034400224685669"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/embeddings_bidirectional_lstm_masking.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-25 20:30:10--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-12-25 20:30:10--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-12-25 20:30:10--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.14MB/s    in 2m 39s  \n",
      "\n",
      "2023-12-25 20:32:50 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "caution: filename not matched:  data/\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip -d data/glove\n",
    "!rm glove.6B.zip\n",
    "!rm data/glove/glove.6B.50d.txt\n",
    "!rm data/glove/glove.6B.200d.txt\n",
    "!rm data/glove/glove.6B.300d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use Glove embeddings\n",
    "\n",
    "path_to_embeddings = './data/glove/glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "with open(path_to_embeddings) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(max_tokens, \n",
    "                                   embedding_dim, \n",
    "                                   embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "                                   trainable=False, \n",
    "                                   mask_zero=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_14 (Embedding)    (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirecti  (None, 64)                34048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2034113 (7.76 MB)\n",
      "Trainable params: 34113 (133.25 KB)\n",
      "Non-trainable params: 2000000 (7.63 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 78s 117ms/step - loss: 0.6332 - binary_accuracy: 0.6431 - val_loss: 0.5393 - val_binary_accuracy: 0.7612\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.5151 - binary_accuracy: 0.7639 - val_loss: 0.4882 - val_binary_accuracy: 0.7876\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 61s 98ms/step - loss: 0.4572 - binary_accuracy: 0.7995 - val_loss: 0.4197 - val_binary_accuracy: 0.8224\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 61s 97ms/step - loss: 0.4170 - binary_accuracy: 0.8214 - val_loss: 0.3736 - val_binary_accuracy: 0.8488\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3982 - binary_accuracy: 0.8326 - val_loss: 0.4284 - val_binary_accuracy: 0.8094\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 60s 97ms/step - loss: 0.3766 - binary_accuracy: 0.8430 - val_loss: 0.3639 - val_binary_accuracy: 0.8526\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3584 - binary_accuracy: 0.8521 - val_loss: 0.3881 - val_binary_accuracy: 0.8516\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 61s 97ms/step - loss: 0.3411 - binary_accuracy: 0.8583 - val_loss: 0.3281 - val_binary_accuracy: 0.8660\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3280 - binary_accuracy: 0.8666 - val_loss: 0.3457 - val_binary_accuracy: 0.8522\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 60s 97ms/step - loss: 0.3151 - binary_accuracy: 0.8713 - val_loss: 0.3144 - val_binary_accuracy: 0.8758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x9c8bdc850>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/glove_embedding_sequence_model.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(int_train_ds,\n",
    "          epochs=10,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 32s 39ms/step - loss: 0.3234 - binary_accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8658800721168518"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/glove_embedding_sequence_model.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode\n",
    "\n",
    "def self_attention(input_sequence):\n",
    "    \n",
    "    output = np.zeros_like(input_sequence)\n",
    "\n",
    "    for i, pivot_vector in enumerate(input_sequence):\n",
    "        scores = np.zeros(shape=(len(input_sequence),))\n",
    "\n",
    "        for j, vector in enumerate(input_sequence):\n",
    "            scores[j] = np.dot(pivot_vector, vector.T)\n",
    "        \n",
    "        scores /= np.sqrt(input_sequence.shape[1])\n",
    "        scores = np.softmax(scores)\n",
    "\n",
    "        new_pivot_representation = np.zeros_like(pivot_vector)\n",
    "\n",
    "        for j, vector in enumerate(input_sequence):\n",
    "            new_pivot_representation += vector * scores[j]\n",
    "        \n",
    "        output[i] = new_pivot_representation\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras way: the Multi-head Attention Layer\n",
    "\n",
    "num_heads = 4\n",
    "embed_dim = 256\n",
    "mha_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "outputs = mha_layer(inputs, inputs, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Transformer Encoder: A useful generic encoder that is useful for learning representations\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class TransformerEncoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=activations.relu),\n",
    "                                            layers.Dense(embed_dim)])\n",
    "        self.layernorm_1 = layers.LayerNormalization()                      \n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "\n",
    "        return self.layernorm_2(proj_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'dense_dim': self.dense_dim\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use layer normalization (each sequence in batch normalized independently for a layer) for sequence data because batch normalization does not work well for sequences.\n",
    "\n",
    "def layer_normalization(batch_of_sequences):                          # Input shape: (batch_size, sequence_length, embedding_dim)\n",
    "    mean = np.mean(batch_of_sequences, keepdims=True, axis=-1)\n",
    "    variance = np.var(batch_of_sequences, keepdims=True, axis=-1)\n",
    "    \n",
    "    return (batch_of_sequences - mean) / variance\n",
    "\n",
    "def batch_normalization(batch_of_images):                             # Input shape: (batch_size, height, width, channels)\n",
    "    mean = np.mean(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
    "    variance = np.var(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
    "    \n",
    "    return (batch_of_images - mean) / variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_18 (Embedding)    (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tra  (None, None, 256)         543776    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 256)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5664033 (21.61 MB)\n",
      "Trainable params: 5664033 (21.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)                            # TransformerEncoder returns full sequences. We need to reduce each sequence to a vector for classification.\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 445s 700ms/step - loss: 0.4816 - binary_accuracy: 0.7677 - val_loss: 0.3517 - val_binary_accuracy: 0.8460\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 404s 645ms/step - loss: 0.3718 - binary_accuracy: 0.8382 - val_loss: 0.3355 - val_binary_accuracy: 0.8532\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 397s 636ms/step - loss: 0.3332 - binary_accuracy: 0.8583 - val_loss: 0.3013 - val_binary_accuracy: 0.8702\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 401s 641ms/step - loss: 0.2962 - binary_accuracy: 0.8760 - val_loss: 0.2957 - val_binary_accuracy: 0.8746\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 393s 628ms/step - loss: 0.2551 - binary_accuracy: 0.8952 - val_loss: 0.3043 - val_binary_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 391s 625ms/step - loss: 0.2137 - binary_accuracy: 0.9152 - val_loss: 0.3064 - val_binary_accuracy: 0.8764\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 390s 624ms/step - loss: 0.1744 - binary_accuracy: 0.9335 - val_loss: 0.3318 - val_binary_accuracy: 0.8714\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 391s 625ms/step - loss: 0.1402 - binary_accuracy: 0.9475 - val_loss: 0.3159 - val_binary_accuracy: 0.8762\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 394s 631ms/step - loss: 0.1051 - binary_accuracy: 0.9628 - val_loss: 0.3672 - val_binary_accuracy: 0.8650\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 390s 623ms/step - loss: 0.0763 - binary_accuracy: 0.9744 - val_loss: 0.4195 - val_binary_accuracy: 0.8642\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 389s 622ms/step - loss: 0.0571 - binary_accuracy: 0.9805 - val_loss: 0.4296 - val_binary_accuracy: 0.8618\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 385s 616ms/step - loss: 0.0394 - binary_accuracy: 0.9868 - val_loss: 0.5133 - val_binary_accuracy: 0.8518\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 389s 623ms/step - loss: 0.0253 - binary_accuracy: 0.9923 - val_loss: 0.5313 - val_binary_accuracy: 0.8516\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 385s 616ms/step - loss: 0.0190 - binary_accuracy: 0.9935 - val_loss: 0.5462 - val_binary_accuracy: 0.8584\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 383s 612ms/step - loss: 0.0120 - binary_accuracy: 0.9965 - val_loss: 0.6205 - val_binary_accuracy: 0.8546\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 381s 610ms/step - loss: 0.0064 - binary_accuracy: 0.9983 - val_loss: 0.6979 - val_binary_accuracy: 0.8548\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 380s 609ms/step - loss: 0.0076 - binary_accuracy: 0.9978 - val_loss: 0.6952 - val_binary_accuracy: 0.8556\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 382s 611ms/step - loss: 0.0051 - binary_accuracy: 0.9985 - val_loss: 0.7336 - val_binary_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 377s 603ms/step - loss: 0.0032 - binary_accuracy: 0.9990 - val_loss: 0.7671 - val_binary_accuracy: 0.8594\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 382s 611ms/step - loss: 0.0049 - binary_accuracy: 0.9984 - val_loss: 0.8006 - val_binary_accuracy: 0.8498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x9c9c7bd50>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/transformer_encoder.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(int_train_ds,\n",
    "          epochs=20,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 169s 214ms/step - loss: 0.3281 - binary_accuracy: 0.8598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.859760046005249"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/transformer_encoder.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_21 (Embedding)    (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " transformer_encoder_2 (Tra  (None, None, 100)         87632     \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 100)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2087733 (7.96 MB)\n",
      "Trainable params: 87733 (342.71 KB)\n",
      "Non-trainable params: 2000000 (7.63 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tranformer Encoder with glove embeddings\n",
    "\n",
    "vocab_size = 20000\n",
    "embed_dim = 100\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "embedding_matrix = np.zeros((max_tokens, embed_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "x = layers.Embedding(vocab_size, \n",
    "                     embed_dim, \n",
    "                     embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "                     trainable=False, \n",
    "                     mask_zero=False)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)                            # TransformerEncoder returns full sequences. We need to reduce each sequence to a vector for classification.\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 204s 308ms/step - loss: 0.5513 - binary_accuracy: 0.7174 - val_loss: 0.3789 - val_binary_accuracy: 0.8364\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 164s 262ms/step - loss: 0.3935 - binary_accuracy: 0.8283 - val_loss: 0.3327 - val_binary_accuracy: 0.8600\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 166s 265ms/step - loss: 0.3656 - binary_accuracy: 0.8411 - val_loss: 0.3121 - val_binary_accuracy: 0.8676\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 158s 252ms/step - loss: 0.3454 - binary_accuracy: 0.8483 - val_loss: 0.3149 - val_binary_accuracy: 0.8690\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 163s 260ms/step - loss: 0.3340 - binary_accuracy: 0.8573 - val_loss: 0.2940 - val_binary_accuracy: 0.8810\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 155s 247ms/step - loss: 0.3231 - binary_accuracy: 0.8603 - val_loss: 0.3091 - val_binary_accuracy: 0.8658\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 166s 266ms/step - loss: 0.3104 - binary_accuracy: 0.8665 - val_loss: 0.2907 - val_binary_accuracy: 0.8822\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.3055 - binary_accuracy: 0.8690 - val_loss: 0.2931 - val_binary_accuracy: 0.8794\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 162s 259ms/step - loss: 0.2981 - binary_accuracy: 0.8729 - val_loss: 0.2858 - val_binary_accuracy: 0.8818\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 161s 257ms/step - loss: 0.2942 - binary_accuracy: 0.8748 - val_loss: 0.2826 - val_binary_accuracy: 0.8830\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2848 - binary_accuracy: 0.8801 - val_loss: 0.2917 - val_binary_accuracy: 0.8782\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 162s 259ms/step - loss: 0.2788 - binary_accuracy: 0.8837 - val_loss: 0.2802 - val_binary_accuracy: 0.8864\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 160s 256ms/step - loss: 0.2741 - binary_accuracy: 0.8866 - val_loss: 0.2827 - val_binary_accuracy: 0.8842\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 166s 266ms/step - loss: 0.2660 - binary_accuracy: 0.8885 - val_loss: 0.2796 - val_binary_accuracy: 0.8854\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 156s 250ms/step - loss: 0.2566 - binary_accuracy: 0.8917 - val_loss: 0.2853 - val_binary_accuracy: 0.8828\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.2515 - binary_accuracy: 0.8955 - val_loss: 0.2866 - val_binary_accuracy: 0.8810\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 156s 249ms/step - loss: 0.2460 - binary_accuracy: 0.8993 - val_loss: 0.3176 - val_binary_accuracy: 0.8664\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.2393 - binary_accuracy: 0.9020 - val_loss: 0.2920 - val_binary_accuracy: 0.8812\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 157s 252ms/step - loss: 0.2330 - binary_accuracy: 0.9035 - val_loss: 0.3116 - val_binary_accuracy: 0.8726\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.2268 - binary_accuracy: 0.9082 - val_loss: 0.2930 - val_binary_accuracy: 0.8824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x9ab00bd90>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/transformer_encoder_glove.keras', save_best_only=True)]\n",
    "\n",
    "model.fit(int_train_ds,\n",
    "          epochs=20,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 89s 112ms/step - loss: 0.3165 - binary_accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8664000630378723"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/transformer_encoder_glove.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Embeddings allow us to incorporate sequential structure in the self attention, which is a set operation.\n",
    "# One downside is that sequence length needs to be known in advance.\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim,\n",
    "                                                 output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length,\n",
    "                                                    output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0,\n",
    "                             limit=length,\n",
    "                             delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "\n",
    "        return embedded_tokens + embedded_positions\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'output_dim': self.output_dim,\n",
    "                       'sequence_length': self.sequence_length,\n",
    "                       'input_dim': self.input_dim}) \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " positional_embedding_18 (P  (None, None, 256)         5273600   \n",
      " ositionalEmbedding)                                             \n",
      "                                                                 \n",
      " transformer_encoder_19 (Tr  (None, None, 256)         543776    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 256)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5817633 (22.19 MB)\n",
      "Trainable params: 5817633 (22.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "sequence_length = 600\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "x = PositionalEmbedding(sequence_length=sequence_length,\n",
    "                        input_dim=vocab_size,\n",
    "                        output_dim=embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim=embed_dim,\n",
    "                       dense_dim=dense_dim,\n",
    "                       num_heads=num_heads)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(),\n",
    "              loss=losses.BinaryCrossentropy(),\n",
    "              metrics=[metrics.BinaryAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 506s 793ms/step - loss: 0.5186 - binary_accuracy: 0.7392 - val_loss: 0.3123 - val_binary_accuracy: 0.8784\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 432s 691ms/step - loss: 0.3091 - binary_accuracy: 0.8747 - val_loss: 0.3015 - val_binary_accuracy: 0.8746\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 419s 671ms/step - loss: 0.2502 - binary_accuracy: 0.9025 - val_loss: 0.3019 - val_binary_accuracy: 0.8884\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 415s 663ms/step - loss: 0.2047 - binary_accuracy: 0.9212 - val_loss: 0.3704 - val_binary_accuracy: 0.8620\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 413s 661ms/step - loss: 0.1770 - binary_accuracy: 0.9337 - val_loss: 0.3034 - val_binary_accuracy: 0.8928\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 422s 676ms/step - loss: 0.1539 - binary_accuracy: 0.9418 - val_loss: 0.3093 - val_binary_accuracy: 0.8964\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 421s 673ms/step - loss: 0.1321 - binary_accuracy: 0.9511 - val_loss: 0.4135 - val_binary_accuracy: 0.8898\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 418s 669ms/step - loss: 0.1183 - binary_accuracy: 0.9561 - val_loss: 0.3796 - val_binary_accuracy: 0.8944\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 408s 652ms/step - loss: 0.1049 - binary_accuracy: 0.9627 - val_loss: 0.4546 - val_binary_accuracy: 0.8930\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 421s 674ms/step - loss: 0.0890 - binary_accuracy: 0.9677 - val_loss: 0.6616 - val_binary_accuracy: 0.8842\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 405s 648ms/step - loss: 0.0795 - binary_accuracy: 0.9717 - val_loss: 0.8245 - val_binary_accuracy: 0.8412\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 400s 640ms/step - loss: 0.0653 - binary_accuracy: 0.9770 - val_loss: 0.6747 - val_binary_accuracy: 0.8866\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 403s 646ms/step - loss: 0.0590 - binary_accuracy: 0.9794 - val_loss: 0.4475 - val_binary_accuracy: 0.8842\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 400s 639ms/step - loss: 0.0485 - binary_accuracy: 0.9839 - val_loss: 0.7238 - val_binary_accuracy: 0.8842\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 401s 642ms/step - loss: 0.0387 - binary_accuracy: 0.9869 - val_loss: 0.8260 - val_binary_accuracy: 0.8864\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 406s 650ms/step - loss: 0.0318 - binary_accuracy: 0.9899 - val_loss: 0.8361 - val_binary_accuracy: 0.8862\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 402s 644ms/step - loss: 0.0296 - binary_accuracy: 0.9923 - val_loss: 0.8541 - val_binary_accuracy: 0.8846\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 389s 622ms/step - loss: 0.0228 - binary_accuracy: 0.9929 - val_loss: 0.9105 - val_binary_accuracy: 0.8840\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 387s 619ms/step - loss: 0.0232 - binary_accuracy: 0.9934 - val_loss: 0.9032 - val_binary_accuracy: 0.8836\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 385s 617ms/step - loss: 0.0179 - binary_accuracy: 0.9951 - val_loss: 1.2748 - val_binary_accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x70638f1f10>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('ckpts/full_transformer_encoder.keras', save_best_only=True)]\n",
    "model.fit(int_train_ds,\n",
    "          epochs=20,\n",
    "          validation_data=int_val_ds,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 178s 222ms/step - loss: 0.3232 - binary_accuracy: 0.8668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8667600750923157"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('ckpts/full_transformer_encoder.keras')\n",
    "model.evaluate(int_test_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence: Translating English to Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-30 18:59:10--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.65.251, 142.250.81.251, 142.250.72.123, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.65.251|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2638744 (2.5M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   2.52M  2.35MB/s    in 1.1s    \n",
      "\n",
      "2023-12-30 18:59:11 (2.35 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip -d data\n",
    "!rm spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Drop it!', '[start]Suéltalo.[end]')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/spa-eng/spa.txt') as f:\n",
    "    lines = f.read().split('\\n')[:-1]\n",
    "\n",
    "text_pairs = []\n",
    "\n",
    "for line in lines:\n",
    "    english, spanish = line.split('\\t')\n",
    "    spanish = '[start]' + spanish + '[end]'\n",
    "    text_pairs.append((english, spanish))\n",
    "\n",
    "text_pairs[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83276, 17844, 17844)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n",
    "\n",
    "len(train_pairs), len(val_pairs), len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing string standardization for text vectorization layer. We want to also eliminate '¿' but do not wish to eliminate '[', ']' due to their meaningful use in [start], [end] tokens\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + '¿'\n",
    "strip_chars = strip_chars.replace('[', '')\n",
    "strip_chars = strip_chars.replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_string):\n",
    "\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    output = tf.strings.regex_replace(lowercase, f'[{re.escape(strip_chars)}]', '')\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "source_vectorization = layers.TextVectorization(max_tokens=vocab_size,\n",
    "                                                output_mode='int',\n",
    "                                                output_sequence_length=sequence_length)\n",
    "\n",
    "target_vectorization = layers.TextVectorization(max_tokens=vocab_size,\n",
    "                                                output_mode='int',\n",
    "                                                output_sequence_length=sequence_length + 1,\n",
    "                                                standardize=custom_standardization)\n",
    "\n",
    "\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "\n",
    "    return {'english': eng, 'spanish':spa[:, :-1]}, spa[:, 1:]\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "test_ds = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"english\"].shape: (64, 20)\n",
      "inputs[\"spanish\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 20:17:36.278935: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"english\"].shape: {inputs[\"english\"].shape}')\n",
    "    print(f'inputs[\"spanish\"].shape: {inputs[\"spanish\"].shape}')\n",
    "    print(f'targets.shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
