{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.layers.Dense(512, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.layers.core.dense.Dense"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.array([[[-3, 3, -3],\n",
    "            [3, -3, 3],\n",
    "            [3, 3, -3]],\n",
    "        [[4, 4, 4],\n",
    "        [4, 4, 4],\n",
    "        [4, 4, 4]]])\n",
    "\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "\n",
    "    x, y = x.copy(), y.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = x[i,j] + y[i,j]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(y, axis=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_vector(x,y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[j]\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x,y)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x,y):\n",
    "    z = 0. \n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10314316 0.41923467 0.50320051 0.72602344 0.27777207 0.17651648]\n",
      " [0.16083233 0.53805927 0.67390177 0.97285118 0.31434391 0.29593489]\n",
      " [0.25718475 0.69835304 0.92038317 0.49299886 0.44024203 0.15946456]\n",
      " [0.24948926 1.0610131  1.38097855 1.17197083 0.84085289 0.17317685]\n",
      " [0.25351602 0.81330438 0.91775186 0.90994554 0.49426909 0.21996989]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((5,4))\n",
    "y = np.random.random((4,6))\n",
    "\n",
    "print(np.matmul(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "\n",
    "    z = np.zeros(x.shape[0], y.shape[1])\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            z[i, j] += naive_vector_dot(x[i, :], y[:, j])\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Transforms\n",
    "\n",
    "from math import cos, sin\n",
    "\n",
    "def counter_clockwise_rotate(vector, theta):\n",
    "    R = [[cos(theta), - sin(theta)],\n",
    "         [sin(theta), cos(theta)]]\n",
    "    \n",
    "    return naive_matrix_vector_dot(R, vector)\n",
    "\n",
    "def scale(horiz_factor, vert_factor, vector):\n",
    "\n",
    "    S = [[horiz_factor, 0],\n",
    "         [0, vert_factor]]\n",
    "    \n",
    "    return naive_matrix_vector_dot(S, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transforms : Combination of a linear transform and a translation (W.x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_momentum(current_parameters, past_velocity, momentum, learning_rate):\n",
    "    loss = current_parameters['loss']\n",
    "    while loss > 0.01:\n",
    "        w = current_parameters['w']\n",
    "        loss = current_parameters['loss']\n",
    "        gradient = current_parameters['gradient']\n",
    "\n",
    "        velocity = past_velocity * momentum - learning_rate * gradient\n",
    "        w = w + momentum * velocity - learning_rate * gradient\n",
    "        past_velocity = velocity\n",
    "        update_parameters(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x,y):\n",
    "    pass\n",
    "\n",
    "def f(x):\n",
    "    return x\n",
    "\n",
    "def g(x):\n",
    "    return x\n",
    "\n",
    "def h(x):\n",
    "    return x\n",
    "\n",
    "def j(x):\n",
    "    return x\n",
    "\n",
    "def fg(x):\n",
    "    return f(g(x))\n",
    "\n",
    "def fghj(x):\n",
    "    return f(g(h(j(x))))\n",
    "\n",
    "def chain_diff(x):\n",
    "    y = fghj(x)\n",
    "    grad(y, x) == grad(y, g(h(j(x)))) * grad(g(h(j(x))), h(j(x))) * grad(h(j(x)), j(x)) * grad(j(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:21:44.569990: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-04 10:21:44.570407: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "\n",
    "print(grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(tf.random.uniform((2,2)))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "\n",
    "print(grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[0.2833612, 0.2833612],\n",
      "       [1.2526826, 1.2526826]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.uniform((2,2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2,2))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W,b])\n",
    "print(grad_of_y_wrt_W_and_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255.\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:45:47.724494: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-07-04 10:45:47.995650: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 5s 7ms/step - loss: 0.2547 - accuracy: 0.9262\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1026 - accuracy: 0.9698\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0672 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0489 - accuracy: 0.9854\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0366 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286eb9940>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveDense:\n",
    "\n",
    "    def __init__(self, input_size, output_size, activation) -> None:\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0., maxval=1e-1)\n",
    "        self.w = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size, )\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.w) + self.b)\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.w, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x \n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images \n",
    "        self.labels = labels \n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "    \n",
    "    def next(self):\n",
    "\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(gradients, weights, learning_rate=1e-3, use_optimizer=True):\n",
    "\n",
    "    if use_optimizer:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        optimizer.apply_gradients(zip(gradients, weights))\n",
    "    else:\n",
    "        for g, w in zip(gradients, weights):\n",
    "            w.assign_sub(g * learning_rate)      # Tensorflow Variable equivalent of \"-=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    \n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights, use_optimizer=True)\n",
    "    \n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_i in range(epochs):\n",
    "        print(f'Epoch {epoch_i}')\n",
    "        batch_generator = BatchGenerator(images, labels, batch_size)\n",
    "\n",
    "        for batch_i in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch=images_batch, labels_batch=labels_batch)\n",
    "            if batch_i % 100 == 0:\n",
    "                print(f'loss at batch {batch_i}: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 0.45\n",
      "loss at batch 100: 0.43\n",
      "loss at batch 200: 0.37\n",
      "loss at batch 300: 0.45\n",
      "loss at batch 400: 0.55\n",
      "Epoch 1\n",
      "loss at batch 0: 0.44\n",
      "loss at batch 100: 0.42\n",
      "loss at batch 200: 0.36\n",
      "loss at batch 300: 0.44\n",
      "loss at batch 400: 0.54\n",
      "Epoch 2\n",
      "loss at batch 0: 0.43\n",
      "loss at batch 100: 0.41\n",
      "loss at batch 200: 0.36\n",
      "loss at batch 300: 0.43\n",
      "loss at batch 400: 0.54\n",
      "Epoch 3\n",
      "loss at batch 0: 0.43\n",
      "loss at batch 100: 0.40\n",
      "loss at batch 200: 0.35\n",
      "loss at batch 300: 0.42\n",
      "loss at batch 400: 0.53\n",
      "Epoch 4\n",
      "loss at batch 0: 0.42\n",
      "loss at batch 100: 0.39\n",
      "loss at batch 200: 0.34\n",
      "loss at batch 300: 0.42\n",
      "loss at batch 400: 0.53\n",
      "Epoch 5\n",
      "loss at batch 0: 0.41\n",
      "loss at batch 100: 0.38\n",
      "loss at batch 200: 0.34\n",
      "loss at batch 300: 0.41\n",
      "loss at batch 400: 0.52\n",
      "Epoch 6\n",
      "loss at batch 0: 0.41\n",
      "loss at batch 100: 0.38\n",
      "loss at batch 200: 0.33\n",
      "loss at batch 300: 0.41\n",
      "loss at batch 400: 0.52\n",
      "Epoch 7\n",
      "loss at batch 0: 0.40\n",
      "loss at batch 100: 0.37\n",
      "loss at batch 200: 0.33\n",
      "loss at batch 300: 0.40\n",
      "loss at batch 400: 0.51\n",
      "Epoch 8\n",
      "loss at batch 0: 0.40\n",
      "loss at batch 100: 0.36\n",
      "loss at batch 200: 0.32\n",
      "loss at batch 300: 0.40\n",
      "loss at batch 400: 0.51\n",
      "Epoch 9\n",
      "loss at batch 0: 0.39\n",
      "loss at batch 100: 0.36\n",
      "loss at batch 200: 0.32\n",
      "loss at batch 300: 0.39\n",
      "loss at batch 400: 0.50\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images).numpy()\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "matches = pred_labels == test_labels\n",
    "print(f'accuracy: {matches.mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbb51ecd76dc0a26d45057fabec12a8718b222197311b332abfee31d181a512e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
